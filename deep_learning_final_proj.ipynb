{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d045187c-69b2-4963-9663-ceabd965776c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#import numpy as np\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, classification_report\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c446ed6-75d0-422e-91c0-c815a106706e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_images_with_tf(image_paths, labels, images_mmap_path, labels_mmap_path, batch_size=500):\n",
    "    total_images = len(image_paths)\n",
    "    print(f\"\\nProcessing {total_images} images for memory-mapped storage...\")\n",
    "\n",
    "    #########################################\n",
    "    # Define image shape and dtype for memory-mapped storage\n",
    "    image_shape = (256, 256, 3)\n",
    "    dtype = 'float32'\n",
    "\n",
    "    # Create memory-mapped arrays for images and labels\n",
    "    images_mmap = np.memmap(images_mmap_path, dtype=dtype, mode='w+', shape=(total_images, *image_shape))\n",
    "    labels_mmap = np.memmap(labels_mmap_path, dtype='int32', mode='w+', shape=(total_images,))\n",
    "\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((image_paths, labels))\n",
    "\n",
    "    def _load_and_preprocess_image(file_path, label):\n",
    "        try:\n",
    "            img = tf.io.read_file(file_path)\n",
    "            img = tf.io.decode_image(img, channels=3, expand_animations=False)\n",
    "            img.set_shape([None, None, 3])\n",
    "            img = tf.image.resize(img, [256, 256])\n",
    "            img = tf.cast(img, tf.float32) / 255.0\n",
    "            return img, label\n",
    "        except Exception as e:\n",
    "            tf.print(f\"Error processing image {file_path}: {e}\")\n",
    "            img = tf.zeros([256, 256, 3], dtype=tf.float32)\n",
    "            return img, label\n",
    "\n",
    "    dataset = dataset.map(_load_and_preprocess_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    dataset = dataset.prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "    idx = 0\n",
    "    for batch_imgs, batch_labels in tqdm(dataset, total=(total_images // batch_size) + 1, desc=\"Processing Images\"):\n",
    "        batch_imgs_np = batch_imgs.numpy()\n",
    "        batch_labels_np = batch_labels.numpy()\n",
    "        batch_size_actual = batch_imgs_np.shape[0]\n",
    "        images_mmap[idx:idx+batch_size_actual] = batch_imgs_np\n",
    "        labels_mmap[idx:idx+batch_size_actual] = batch_labels_np\n",
    "        idx += batch_size_actual\n",
    "\n",
    "        # Flush changes to memory-mapped file to disk and clear memory\n",
    "        images_mmap.flush()\n",
    "        labels_mmap.flush()\n",
    "        gc.collect()\n",
    "\n",
    "    del images_mmap\n",
    "    del labels_mmap\n",
    "    print(f\"Finished processing {total_images} images into {images_mmap_path} and {labels_mmap_path}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "53b679ee-ebeb-4bef-9cd4-1e4d1c9fffac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening zip file: SDNET2018.zip\n",
      "\n",
      "Found 11595 images in subfolder 'SDNET2018/D/UD'. Sampling 2319 images for label 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting to temp_extracted: 100%|███████████████████████████████████████████████| 2319/2319 [00:03<00:00, 596.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Found 1260 images in subfolder 'SDNET2018/D/CD'. Sampling 252 images for label 1.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting to temp_extracted: 100%|█████████████████████████████████████████████████| 252/252 [00:00<00:00, 649.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Found 21726 images in subfolder 'SDNET2018/P/UP'. Sampling 4345 images for label 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting to temp_extracted: 100%|███████████████████████████████████████████████| 4345/4345 [00:06<00:00, 644.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Found 2608 images in subfolder 'SDNET2018/P/CP'. Sampling 521 images for label 1.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting to temp_extracted: 100%|█████████████████████████████████████████████████| 521/521 [00:01<00:00, 471.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing 2571 images for memory-mapped storage...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images: 100%|█████████████████████████████████████████████████████████████████| 6/6 [00:21<00:00,  3.61s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished processing 2571 images into images_d_mmap.npy and labels_d.npy.\n",
      "\n",
      "Processing 4866 images for memory-mapped storage...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images: 100%|███████████████████████████████████████████████████████████████| 10/10 [00:40<00:00,  4.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished processing 4866 images into images_p_mmap.npy and labels_p.npy.\n",
      "\n",
      "Filenames and labels saved for 'D' and 'P' folders.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import shutil\n",
    "import gc\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import logging\n",
    "import random\n",
    "\n",
    "# --------------------- Configuration ---------------------\n",
    "\n",
    "# Configure logging to capture errors during processing\n",
    "logging.basicConfig(\n",
    "    filename='data_processing.log',\n",
    "    level=logging.ERROR,\n",
    "    format='%(asctime)s:%(levelname)s:%(message)s'\n",
    ")\n",
    "\n",
    "# Define paths for memory-mapped arrays\n",
    "IMAGES_D_MEMMAP_PATH = 'images_d_mmap.npy'\n",
    "LABELS_D_MEMMAP_PATH = 'labels_d.npy'\n",
    "IMAGES_P_MEMMAP_PATH = 'images_p_mmap.npy'\n",
    "LABELS_P_MEMMAP_PATH = 'labels_p.npy'\n",
    "\n",
    "# Temporary extraction directory\n",
    "TEMP_DIR = \"temp_extracted\"\n",
    "\n",
    "# Sampling fraction (20%)\n",
    "SAMPLE_FRACTION = .2\n",
    "\n",
    "# Seed for reproducibility\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "# --------------------- Setup ---------------------\n",
    "\n",
    "# Ensure temporary directory exists\n",
    "os.makedirs(TEMP_DIR, exist_ok=True)\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "random.seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n",
    "tf.random.set_seed(RANDOM_SEED)\n",
    "\n",
    "# Enable GPU processing for TensorFlow, if available\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        print(f\"{len(gpus)} GPU(s) detected and memory growth enabled.\")\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "\n",
    "# --------------------- Helper Functions ---------------------\n",
    "\n",
    "def is_image_file(filename):\n",
    "    \"\"\"\n",
    "    Check if a file is an image based on its extension.\n",
    "    \n",
    "    Parameters:\n",
    "    - filename (str): Name of the file.\n",
    "    \n",
    "    Returns:\n",
    "    - bool: True if the file is an image, False otherwise.\n",
    "    \"\"\"\n",
    "    return filename.lower().endswith(('.jpg', '.jpeg', '.png'))\n",
    "\n",
    "def extract_images_and_labels(zip_path, image_filenames, temp_dir, label):\n",
    "    \"\"\"\n",
    "    Extract images from a zip file to a temporary directory and assign labels.\n",
    "    \n",
    "    Parameters:\n",
    "    - zip_path (str): Path to the zip file.\n",
    "    - image_filenames (list): List of image file paths within the zip.\n",
    "    - temp_dir (str): Directory to extract images to.\n",
    "    - label (int): Label to assign to all extracted images.\n",
    "    \n",
    "    Returns:\n",
    "    - extracted_paths (list): List of paths to the extracted images.\n",
    "    - labels (list): List of labels corresponding to the extracted images.\n",
    "    \"\"\"\n",
    "    extracted_paths = []\n",
    "    labels = []\n",
    "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "        for img_path in tqdm(image_filenames, desc=f\"Extracting to {temp_dir}\"):\n",
    "            try:\n",
    "                zip_ref.extract(img_path, temp_dir)\n",
    "                extracted_file_path = os.path.join(temp_dir, img_path)\n",
    "                extracted_paths.append(extracted_file_path)\n",
    "                labels.append(label)  # Assign the passed label\n",
    "            except Exception as e:\n",
    "                logging.error(f\"Error extracting {img_path}: {e}\")\n",
    "                continue\n",
    "    return extracted_paths, labels\n",
    "\n",
    "# --------------------- Main Processing Function ---------------------\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Main function to process images from 'D' and 'P' folders within 'SDNET2018.zip'.\n",
    "    It samples 20% of images from each subfolder, assigns labels, processes images,\n",
    "    and saves them into separate memory-mapped files.\n",
    "    \"\"\"\n",
    "    zip_path = 'SDNET2018.zip'  # Path to your zip file\n",
    "    batch_size = 500  # Adjust based on available memory\n",
    "\n",
    "    # Define mapping from subfolders to labels\n",
    "    subfolder_label_mapping = {\n",
    "        'SDNET2018/D/UD': 0,  # Uncracked\n",
    "        'SDNET2018/D/CD': 1,  # Cracked\n",
    "        'SDNET2018/P/UP': 0,  # Uncracked\n",
    "        'SDNET2018/P/CP': 1   # Cracked\n",
    "    }\n",
    "\n",
    "    # Extract all filenames from the zip file\n",
    "    print(f\"Opening zip file: {zip_path}\")\n",
    "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "        all_filenames = zip_ref.namelist()\n",
    "\n",
    "    # Function to filter image filenames from a specific subfolder\n",
    "    def get_image_filenames(subfolder):\n",
    "        prefix = subfolder + '/'\n",
    "        return [f for f in all_filenames if f.startswith(prefix) and is_image_file(f)]\n",
    "\n",
    "    # Initialize dictionaries to hold image paths and labels for D and P\n",
    "    data = {\n",
    "        'D': {'image_paths': [], 'labels': []},\n",
    "        'P': {'image_paths': [], 'labels': []}\n",
    "    }\n",
    "\n",
    "    # Iterate over each subfolder and process images\n",
    "    for subfolder, label in subfolder_label_mapping.items():\n",
    "        image_filenames = get_image_filenames(subfolder)\n",
    "        total_images = len(image_filenames)\n",
    "        sample_size = max(1, int(total_images * SAMPLE_FRACTION))  # Ensure at least 1 image is sampled\n",
    "\n",
    "        # Randomly sample 20% of the images\n",
    "        sampled_filenames = random.sample(image_filenames, sample_size)\n",
    "\n",
    "        print(f\"\\nFound {total_images} images in subfolder '{subfolder}'. Sampling {sample_size} images for label {label}.\")\n",
    "\n",
    "        # Extract images and assign labels\n",
    "        image_paths, labels = extract_images_and_labels(zip_path, sampled_filenames, TEMP_DIR, label)\n",
    "\n",
    "        # Determine main folder (D or P) based on subfolder\n",
    "        main_folder = subfolder.split('/')[1]\n",
    "\n",
    "        # Append to the respective main folder's data\n",
    "        data[main_folder]['image_paths'].extend(image_paths)\n",
    "        data[main_folder]['labels'].extend(labels)\n",
    "\n",
    "    # Process and save D folder data\n",
    "    if data['D']['image_paths']:\n",
    "        process_images_with_tf(\n",
    "            data['D']['image_paths'],\n",
    "            labels=data['D']['labels'],\n",
    "            images_mmap_path=IMAGES_D_MEMMAP_PATH,\n",
    "            labels_mmap_path=LABELS_D_MEMMAP_PATH,\n",
    "            batch_size=batch_size\n",
    "        )\n",
    "\n",
    "        # Save the filenames and labels for D\n",
    "        np.save('filenames_d.npy', data['D']['image_paths'])\n",
    "        np.save('labels_d.npy', data['D']['labels'])\n",
    "    else:\n",
    "        print(\"\\nNo images found for 'D' folder after sampling.\")\n",
    "\n",
    "    # Process and save P folder data\n",
    "    if data['P']['image_paths']:\n",
    "        process_images_with_tf(\n",
    "            data['P']['image_paths'],\n",
    "            labels=data['P']['labels'],\n",
    "            images_mmap_path=IMAGES_P_MEMMAP_PATH,\n",
    "            labels_mmap_path=LABELS_P_MEMMAP_PATH,\n",
    "            batch_size=batch_size\n",
    "        )\n",
    "\n",
    "        # Save the filenames and labels for P\n",
    "        np.save('filenames_p.npy', data['P']['image_paths'])\n",
    "        np.save('labels_p.npy', data['P']['labels'])\n",
    "    else:\n",
    "        print(\"\\nNo images found for 'P' folder after sampling.\")\n",
    "\n",
    "    # Clear temporary directory\n",
    "    shutil.rmtree(TEMP_DIR)\n",
    "    os.makedirs(TEMP_DIR, exist_ok=True)\n",
    "\n",
    "    # Free up memory\n",
    "    del data\n",
    "    gc.collect()\n",
    "\n",
    "    print(\"\\nFilenames and labels saved for 'D' and 'P' folders.\")\n",
    "\n",
    "# --------------------- Execute Script ---------------------\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "262ad4ca-e1af-4792-9a22-7a08ecfc3da5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded successfully.\n",
      "Train Set D: 2056 samples.\n",
      "Test Set D: 515 samples.\n",
      "Train Set P: 3892 samples.\n",
      "Test Set P: 974 samples.\n",
      "Train Set A (Large and Diverse): 5948 samples.\n",
      "Train Set B (Small and Diverse): 594 samples.\n",
      "Train Set C (D only): 2056 samples.\n",
      "Test Set D (D only): 515 samples.\n",
      "Test Set P (P only): 974 samples.\n",
      "\n",
      "All datasets have been saved successfully.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# Paths for memory-mapped files after processing images\n",
    "IMAGES_D_MEMMAP_PATH = 'images_d_mmap.npy'\n",
    "LABELS_D_MEMMAP_PATH = 'labels_d.npy'\n",
    "IMAGES_P_MEMMAP_PATH = 'images_p_mmap.npy'\n",
    "LABELS_P_MEMMAP_PATH = 'labels_p.npy'\n",
    "\n",
    "# Ensure that necessary files exist\n",
    "if not (os.path.exists(IMAGES_D_MEMMAP_PATH) and os.path.exists(LABELS_D_MEMMAP_PATH) and os.path.exists(IMAGES_P_MEMMAP_PATH) and os.path.exists(LABELS_P_MEMMAP_PATH)):\n",
    "    print(\"Required processed files not found. Make sure to run the image extraction and processing first.\")\n",
    "    exit()\n",
    "\n",
    "# Load labels for datasets D and P\n",
    "labels_d = np.load(LABELS_D_MEMMAP_PATH)\n",
    "labels_p = np.load(LABELS_P_MEMMAP_PATH)\n",
    "\n",
    "# Define the number of images in each set\n",
    "total_images_d = len(labels_d)\n",
    "total_images_p = len(labels_p)\n",
    "\n",
    "# Load images from memory-mapped files\n",
    "images_d = np.memmap(\n",
    "    IMAGES_D_MEMMAP_PATH,\n",
    "    dtype='float32',\n",
    "    mode='r',\n",
    "    shape=(total_images_d, 256, 256, 3)\n",
    ")\n",
    "\n",
    "images_p = np.memmap(\n",
    "    IMAGES_P_MEMMAP_PATH,\n",
    "    dtype='float32',\n",
    "    mode='r',\n",
    "    shape=(total_images_p, 256, 256, 3)\n",
    ")\n",
    "\n",
    "# Verify that the number of labels matches the number of images\n",
    "assert len(labels_d) == total_images_d, \"Mismatch in number of D labels and images.\"\n",
    "assert len(labels_p) == total_images_p, \"Mismatch in number of P labels and images.\"\n",
    "\n",
    "print(\"Data loaded successfully.\")\n",
    "\n",
    "# Split the D data into training and test sets (80% training, 20% testing)\n",
    "train_indices_d, test_indices_d = train_test_split(\n",
    "    np.arange(total_images_d),\n",
    "    test_size=0.20,\n",
    "    random_state=42,\n",
    "    stratify=labels_d\n",
    ")\n",
    "\n",
    "# Extract training and testing images and labels for D\n",
    "train_images_d = images_d[train_indices_d]\n",
    "train_labels_d = labels_d[train_indices_d]\n",
    "test_images_d = images_d[test_indices_d]\n",
    "test_labels_d = labels_d[test_indices_d]\n",
    "\n",
    "print(f\"Train Set D: {len(train_images_d)} samples.\")\n",
    "print(f\"Test Set D: {len(test_images_d)} samples.\")\n",
    "\n",
    "# Split the P data into training and test sets (80% training, 20% testing)\n",
    "train_indices_p, test_indices_p = train_test_split(\n",
    "    np.arange(total_images_p),\n",
    "    test_size=0.20,\n",
    "    random_state=42,\n",
    "    stratify=labels_p\n",
    ")\n",
    "\n",
    "# Extract training and testing images and labels for P\n",
    "train_images_p = images_p[train_indices_p]\n",
    "train_labels_p = labels_p[train_indices_p]\n",
    "test_images_p = images_p[test_indices_p]\n",
    "test_labels_p = labels_p[test_indices_p]\n",
    "\n",
    "print(f\"Train Set P: {len(train_images_p)} samples.\")\n",
    "print(f\"Test Set P: {len(test_images_p)} samples.\")\n",
    "\n",
    "# Combine D and P training data for Train Set A (large and diverse)\n",
    "train_images_A = np.concatenate((train_images_d, train_images_p), axis=0)\n",
    "train_labels_A = np.concatenate((train_labels_d, train_labels_p), axis=0)\n",
    "\n",
    "print(f\"Train Set A (Large and Diverse): {len(train_images_A)} samples.\")\n",
    "\n",
    "# Create a small, diverse training set by taking 10% of Train Set A (Train Set B)\n",
    "fraction_B = 0.10  # 10%\n",
    "num_samples_B = int(len(train_images_A) * fraction_B)\n",
    "\n",
    "# Randomly sample Train Set B from Train Set A\n",
    "indices_B = np.random.choice(len(train_images_A), size=num_samples_B, replace=False)\n",
    "train_images_B = train_images_A[indices_B]\n",
    "train_labels_B = train_labels_A[indices_B]\n",
    "\n",
    "print(f\"Train Set B (Small and Diverse): {len(train_images_B)} samples.\")\n",
    "\n",
    "# Define Train Set C as all D training data\n",
    "train_images_C = train_images_d\n",
    "train_labels_C = train_labels_d\n",
    "\n",
    "print(f\"Train Set C (D only): {len(train_images_C)} samples.\")\n",
    "\n",
    "# Define Test Set D (only D testing data)\n",
    "test_images_D = test_images_d\n",
    "test_labels_D = test_labels_d\n",
    "\n",
    "print(f\"Test Set D (D only): {len(test_images_D)} samples.\")\n",
    "\n",
    "# Define Test Set P (only P testing data)\n",
    "test_images_P = test_images_p\n",
    "test_labels_P = test_labels_p\n",
    "\n",
    "print(f\"Test Set P (P only): {len(test_images_P)} samples.\")\n",
    "\n",
    "# Function to save datasets\n",
    "def save_dataset(images, labels, images_path, labels_path):\n",
    "    np.save(images_path, images)\n",
    "    np.save(labels_path, labels)\n",
    "\n",
    "# Save Train Set A\n",
    "save_dataset(train_images_A, train_labels_A, 'train_set_A_images.npy', 'train_set_A_labels.npy')\n",
    "\n",
    "# Save Train Set B\n",
    "save_dataset(train_images_B, train_labels_B, 'train_set_B_images.npy', 'train_set_B_labels.npy')\n",
    "\n",
    "# Save Train Set C\n",
    "save_dataset(train_images_C, train_labels_C, 'train_set_C_images.npy', 'train_set_C_labels.npy')\n",
    "\n",
    "# Save Test Set D\n",
    "save_dataset(test_images_D, test_labels_D, 'test_set_D_images.npy', 'test_set_D_labels.npy')\n",
    "\n",
    "# Save Test Set P\n",
    "save_dataset(test_images_P, test_labels_P, 'test_set_P_images.npy', 'test_set_P_labels.npy')\n",
    "\n",
    "print(\"\\nAll datasets have been saved successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2c572bf1-119a-4075-96f5-7bcc3bbf3742",
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 4.36 GiB for an array with shape (1169424384,) and data type float32",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Load the datasets\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m train_images_A \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrain_set_A_images.npy\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m train_labels_A \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain_set_A_labels.npy\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      5\u001b[0m train_images_B \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain_set_B_images.npy\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\numpy\\lib\\npyio.py:456\u001b[0m, in \u001b[0;36mload\u001b[1;34m(file, mmap_mode, allow_pickle, fix_imports, encoding, max_header_size)\u001b[0m\n\u001b[0;32m    453\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m.\u001b[39mopen_memmap(file, mode\u001b[38;5;241m=\u001b[39mmmap_mode,\n\u001b[0;32m    454\u001b[0m                                   max_header_size\u001b[38;5;241m=\u001b[39mmax_header_size)\n\u001b[0;32m    455\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 456\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mformat\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_pickle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_pickle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    457\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mpickle_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpickle_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    458\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mmax_header_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_header_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    459\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    460\u001b[0m     \u001b[38;5;66;03m# Try a pickle\u001b[39;00m\n\u001b[0;32m    461\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m allow_pickle:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\numpy\\lib\\format.py:809\u001b[0m, in \u001b[0;36mread_array\u001b[1;34m(fp, allow_pickle, pickle_kwargs, max_header_size)\u001b[0m\n\u001b[0;32m    806\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m isfileobj(fp):\n\u001b[0;32m    808\u001b[0m         \u001b[38;5;66;03m# We can use the fast fromfile() function.\u001b[39;00m\n\u001b[1;32m--> 809\u001b[0m         array \u001b[38;5;241m=\u001b[39m \u001b[43mnumpy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfromfile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcount\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcount\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    810\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    811\u001b[0m         \u001b[38;5;66;03m# This is not a real file. We have to read it the\u001b[39;00m\n\u001b[0;32m    812\u001b[0m         \u001b[38;5;66;03m# memory-intensive way.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    820\u001b[0m         \u001b[38;5;66;03m# not correctly instantiate zero-width string dtypes; see\u001b[39;00m\n\u001b[0;32m    821\u001b[0m         \u001b[38;5;66;03m# https://github.com/numpy/numpy/pull/6430\u001b[39;00m\n\u001b[0;32m    822\u001b[0m         array \u001b[38;5;241m=\u001b[39m numpy\u001b[38;5;241m.\u001b[39mndarray(count, dtype\u001b[38;5;241m=\u001b[39mdtype)\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 4.36 GiB for an array with shape (1169424384,) and data type float32"
     ]
    }
   ],
   "source": [
    "# Load the datasets\n",
    "train_images_A = np.load('train_set_A_images.npy')\n",
    "train_labels_A = np.load('train_set_A_labels.npy')\n",
    "\n",
    "train_images_B = np.load('train_set_B_images.npy')\n",
    "train_labels_B = np.load('train_set_B_labels.npy')\n",
    "\n",
    "train_images_C = np.load('train_set_C_images.npy')\n",
    "train_labels_C = np.load('train_set_C_labels.npy')\n",
    "\n",
    "test_images_D = np.load('test_set_D_images.npy')\n",
    "test_labels_D = np.load('test_set_D_labels.npy')\n",
    "\n",
    "test_images_P = np.load('test_set_P_images.npy')\n",
    "test_labels_P = np.load('test_set_P_labels.npy')\n",
    "\n",
    "# Data Augmentation Layer\n",
    "data_augmentation = tf.keras.Sequential([\n",
    "    tf.keras.layers.RandomFlip('horizontal_and_vertical'),\n",
    "    tf.keras.layers.RandomRotation(0.1),\n",
    "    tf.keras.layers.RandomZoom(0.1)\n",
    "])\n",
    "\n",
    "# Number of Augmented Samples per Cracked Image\n",
    "AUGMENT_PER_IMAGE = 5\n",
    "\n",
    "def augment_cracked_images(images, labels):\n",
    "    augmented_images, augmented_labels = [], []\n",
    "    for i in tqdm(range(len(labels)), desc=\"Augmenting Cracked Images\"):\n",
    "        if labels[i] == 1:  # Only augment cracked images\n",
    "            image = images[i]\n",
    "            for _ in range(AUGMENT_PER_IMAGE):\n",
    "                augmented_image = data_augmentation(tf.expand_dims(image, 0))\n",
    "                augmented_images.append(augmented_image[0].numpy())\n",
    "                augmented_labels.append(1)\n",
    "    return np.array(augmented_images), np.array(augmented_labels)\n",
    "\n",
    "# Function to train and evaluate the model\n",
    "def train_and_evaluate(train_images, train_labels, test_images, test_labels, set_name):\n",
    "    # Augment cracked images\n",
    "    augmented_images, augmented_labels = augment_cracked_images(train_images, train_labels)\n",
    "    train_images_balanced = np.concatenate((train_images, augmented_images), axis=0)\n",
    "    train_labels_balanced = np.concatenate((train_labels, augmented_labels), axis=0)\n",
    "\n",
    "    # Print class distribution after augmentation\n",
    "    train_class_distribution_balanced = Counter(train_labels_balanced)\n",
    "    print(f\"Balanced Training Set Class Distribution for {set_name}: {train_class_distribution_balanced}\")\n",
    "\n",
    "    # Load VGG16 pre-trained model\n",
    "    base_model = VGG16(weights='imagenet', include_top=False, input_shape=(256, 256, 3))\n",
    "    base_model.trainable = False\n",
    "\n",
    "    # Build transfer learning model\n",
    "    model_transfer = models.Sequential([\n",
    "        base_model,\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(128, activation='relu'),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "\n",
    "    model_transfer.compile(optimizer=Adam(learning_rate=0.0005), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    callbacks_transfer = [\n",
    "        ModelCheckpoint(f'best_model_transfer_{set_name}.keras', monitor='val_accuracy', save_best_only=True, verbose=1),\n",
    "        EarlyStopping(monitor='val_accuracy', patience=5, verbose=1, restore_best_weights=True),\n",
    "        ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, verbose=1)\n",
    "    ]\n",
    "\n",
    "    # Train the model\n",
    "    history_transfer = model_transfer.fit(\n",
    "        train_images_balanced,\n",
    "        train_labels_balanced,\n",
    "        validation_data=(test_images, test_labels),\n",
    "        epochs=20,\n",
    "        batch_size=32,\n",
    "        callbacks=callbacks_transfer,\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    # Unfreeze layers and fine-tune\n",
    "    base_model.trainable = True\n",
    "    model_transfer.compile(optimizer=Adam(learning_rate=1e-5), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    history_fine_tune = model_transfer.fit(\n",
    "        train_images_balanced,\n",
    "        train_labels_balanced,\n",
    "        validation_data=(test_images, test_labels),\n",
    "        epochs=20,\n",
    "        batch_size=32,\n",
    "        callbacks=callbacks_transfer,\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    # Evaluate on test set\n",
    "    predictions = model_transfer.predict(test_images)\n",
    "    predicted_labels = (predictions >= 0.15).astype(int).flatten()\n",
    "\n",
    "    # Compute and print confusion matrix and metrics\n",
    "    cm = confusion_matrix(test_labels, predicted_labels)\n",
    "    precision = precision_score(test_labels, predicted_labels, zero_division=0)\n",
    "    recall = recall_score(test_labels, predicted_labels, zero_division=0)\n",
    "    report = classification_report(test_labels, predicted_labels, target_names=['Uncracked', 'Cracked'], zero_division=0)\n",
    "\n",
    "    print(f\"Confusion Matrix ({set_name} Test Set):\")\n",
    "    print(cm)\n",
    "    print(f\"\\nPrecision: {precision:.4f}\")\n",
    "    print(f\"Recall:    {recall:.4f}\")\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(report)\n",
    "\n",
    "    # Plot confusion matrix\n",
    "    plt.figure(figsize=(6, 5))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "                xticklabels=['Uncracked (0)', 'Cracked (1)'],\n",
    "                yticklabels=['Uncracked (0)', 'Cracked (1)'])\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.title(f'Confusion Matrix ({set_name} Test Set)')\n",
    "    plt.show()\n",
    "\n",
    "# Define train and test sets\n",
    "datasets = {\n",
    "    \"Train Set A\": (train_images_A, train_labels_A),\n",
    "    \"Train Set B\": (train_images_B, train_labels_B),\n",
    "    \"Train Set C\": (train_images_C, train_labels_C)\n",
    "}\n",
    "\n",
    "test_sets = {\n",
    "    \"Test Set D\": (test_images_D, test_labels_D),\n",
    "    \"Test Set P\": (test_images_P, test_labels_P)\n",
    "}\n",
    "\n",
    "# Train and evaluate for each combination of train and test sets\n",
    "for train_name, (train_images, train_labels) in datasets.items():\n",
    "    for test_name, (test_images, test_labels) in test_sets.items():\n",
    "        print(f\"\\nTraining {train_name} and Evaluating on {test_name}...\")\n",
    "        train_and_evaluate(train_images, train_labels, test_images, test_labels, f'{train_name}_to_{test_name}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77c90237-b921-4d89-ad89-499967932d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install keras_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d96d712-4e34-4260-9d89-8f244a8b1afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install albumentations\n",
    "#!pip install efficientnet"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
